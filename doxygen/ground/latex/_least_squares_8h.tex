\hypertarget{_least_squares_8h}{\section{/home/jose/\-Code/gui\-Tau/ground/gcs/src/libs/eigen/\-Eigen/src/\-Least\-Squares/\-Least\-Squares.h File Reference}
\label{_least_squares_8h}\index{/home/jose/\-Code/gui\-Tau/ground/gcs/src/libs/eigen/\-Eigen/src/\-Least\-Squares/\-Least\-Squares.\-h@{/home/jose/\-Code/gui\-Tau/ground/gcs/src/libs/eigen/\-Eigen/src/\-Least\-Squares/\-Least\-Squares.\-h}}
}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
{\footnotesize template$<$typename Vector\-Type $>$ }\\\hyperlink{group___u_a_v_objects_plugin_ga444cf2ff3f0ecbe028adce838d373f5c}{void} \hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linear\-Regression} (\hyperlink{ioapi_8h_a787fa3cf048117ba7123753c1e74fcd6}{int} num\-Points, Vector\-Type $\ast$$\ast$\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}, Vector\-Type $\ast$\hyperlink{qxtslotjob_8h_aab161efab0511ea9612b64c40e9852ca}{result}, \hyperlink{ioapi_8h_a787fa3cf048117ba7123753c1e74fcd6}{int} func\-Of\-Others)
\item 
{\footnotesize template$<$typename Vector\-Type , typename Hyperplane\-Type $>$ }\\\hyperlink{group___u_a_v_objects_plugin_ga444cf2ff3f0ecbe028adce838d373f5c}{void} \hyperlink{_least_squares_8h_a5cb0dfbfaedfe2fa9c60678b5cf53b56}{fit\-Hyperplane} (\hyperlink{ioapi_8h_a787fa3cf048117ba7123753c1e74fcd6}{int} num\-Points, Vector\-Type $\ast$$\ast$\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}, Hyperplane\-Type $\ast$\hyperlink{qxtslotjob_8h_aab161efab0511ea9612b64c40e9852ca}{result}, typename \hyperlink{struct_num_traits}{Num\-Traits}$<$ typename Vector\-Type\-::\-Scalar $>$\-::Real $\ast$soundness=0)
\end{DoxyCompactItemize}


\subsection{Function Documentation}
\hypertarget{_least_squares_8h_a5cb0dfbfaedfe2fa9c60678b5cf53b56}{\index{Least\-Squares.\-h@{Least\-Squares.\-h}!fit\-Hyperplane@{fit\-Hyperplane}}
\index{fit\-Hyperplane@{fit\-Hyperplane}!LeastSquares.h@{Least\-Squares.\-h}}
\subsubsection[{fit\-Hyperplane}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Vector\-Type , typename Hyperplane\-Type $>$ {\bf void} fit\-Hyperplane (
\begin{DoxyParamCaption}
\item[{{\bf int}}]{num\-Points, }
\item[{Vector\-Type $\ast$$\ast$}]{points, }
\item[{Hyperplane\-Type $\ast$}]{result, }
\item[{typename {\bf Num\-Traits}$<$ typename Vector\-Type\-::\-Scalar $>$\-::Real $\ast$}]{soundness = {\ttfamily 0}}
\end{DoxyParamCaption}
)}}\label{_least_squares_8h_a5cb0dfbfaedfe2fa9c60678b5cf53b56}
This function is quite similar to \hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linear\-Regression()}, so we refer to the documentation of this function and only list here the differences.

The main difference from \hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linear\-Regression()} is that this function doesn't take a {\itshape func\-Of\-Others} argument. Instead, it finds a general equation of the form \[ r_0 x_0 + \cdots + r_{n-1}x_{n-1} + r_n = 0, \] where $n=Size$, $r_i=retCoefficients[i]$, and we denote by $x_0,\ldots,x_{n-1}$ the n coordinates in the n-\/dimensional space.

Thus, the vector {\itshape ret\-Coefficients} has size $n+1$, which is another difference from \hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linear\-Regression()}.

In practice, this function performs an hyper-\/plane fit in a total least square sense via the following steps\-: 1 -\/ center the data to the mean 2 -\/ compute the covariance matrix 3 -\/ pick the eigenvector corresponding to the smallest eigenvalue of the covariance matrix The ratio of the smallest eigenvalue and the second one gives us a hint about the relevance of the solution. This value is optionally returned in {\itshape soundness}.

\begin{DoxySeeAlso}{See Also}
\hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linear\-Regression()} 
\end{DoxySeeAlso}


Definition at line 143 of file Least\-Squares.\-h.

\hypertarget{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{\index{Least\-Squares.\-h@{Least\-Squares.\-h}!linear\-Regression@{linear\-Regression}}
\index{linear\-Regression@{linear\-Regression}!LeastSquares.h@{Least\-Squares.\-h}}
\subsubsection[{linear\-Regression}]{\setlength{\rightskip}{0pt plus 5cm}template$<$typename Vector\-Type $>$ {\bf void} linear\-Regression (
\begin{DoxyParamCaption}
\item[{{\bf int}}]{num\-Points, }
\item[{Vector\-Type $\ast$$\ast$}]{points, }
\item[{Vector\-Type $\ast$}]{result, }
\item[{{\bf int}}]{func\-Of\-Others}
\end{DoxyParamCaption}
)}}\label{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}
For a set of points, this function tries to express one of the coords as a linear (affine) function of the other coords.

This is best explained by an example. This function works in full generality, for points in a space of arbitrary dimension, and also over the complex numbers, but for this example we will work in dimension 3 over the real numbers (doubles).

So let us work with the following set of 5 points given by their $(x,y,z)$ coordinates\-: 
\begin{DoxyCode}
Vector3d \hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[5];
\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[0] = Vector3d( 3.02, 6.89, -4.32 );
\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[1] = Vector3d( 2.01, 5.39, -3.79 );
\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[2] = Vector3d( 2.41, 6.01, -4.01 );
\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[3] = Vector3d( 2.09, 5.55, -3.86 );
\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points}[4] = Vector3d( 2.58, 6.32, -4.10 );
\end{DoxyCode}
 Suppose that we want to express the second coordinate ( $y$) as a linear expression in $x$ and $z$, that is, \[ y=ax+bz+c \] for some constants $a,b,c$. Thus, we want to find the best possible constants $a,b,c$ so that the plane of equation $y=ax+bz+c$ fits best the five above points. To do that, call this function as follows\-: 
\begin{DoxyCode}
Vector3d coeffs; \textcolor{comment}{// will store the coefficients a, b, c}
\hyperlink{_least_squares_8h_a1db4d54588a78e71f46394f57b4252bd}{linearRegression}(
  5,
  &\hyperlink{glext_8h_ae75d9f560170dfeaadc8718c87f5fbec}{points},
  &coeffs,
  1 \textcolor{comment}{// the coord to express as a function of}
    \textcolor{comment}{// the other ones. 0 means x, 1 means y, 2 means z.}
);
\end{DoxyCode}
 Now the vector {\itshape coeffs} is approximately $( 0.495 , -1.927 , -2.906 )$. Thus, we get $a=0.495, b = -1.927, c = -2.906$. Let us check for instance how near points\mbox{[}0\mbox{]} is from the plane of equation $y=ax+bz+c$. Looking at the coords of points\mbox{[}0\mbox{]}, we see that\-: \[ax+bz+c = 0.495 * 3.02 + (-1.927) * (-4.32) + (-2.906) = 6.91.\] On the other hand, we have $y=6.89$. We see that the values $6.91$ and $6.89$ are near, so points\mbox{[}0\mbox{]} is very near the plane of equation $y=ax+bz+c$.

Let's now describe precisely the parameters\-: 
\begin{DoxyParams}{Parameters}
{\em num\-Points} & the number of points \\
\hline
{\em points} & the array of pointers to the points on which to perform the linear regression \\
\hline
{\em result} & pointer to the vector in which to store the result. This vector must be of the same type and size as the data points. The meaning of its coords is as follows. For brevity, let $n=Size$, $r_i=result[i]$, and $f=funcOfOthers$. Denote by $x_0,\ldots,x_{n-1}$ the n coordinates in the n-\/dimensional space. Then the resulting equation is\-: \[ x_f = r_0 x_0 + \cdots + r_{f-1}x_{f-1} + r_{f+1}x_{f+1} + \cdots + r_{n-1}x_{n-1} + r_n. \] \\
\hline
{\em func\-Of\-Others} & Determines which coord to express as a function of the others. Coords are numbered starting from 0, so that a value of 0 means $x$, 1 means $y$, 2 means $z$, ...\\
\hline
\end{DoxyParams}
\begin{DoxySeeAlso}{See Also}
\hyperlink{_least_squares_8h_a5cb0dfbfaedfe2fa9c60678b5cf53b56}{fit\-Hyperplane()} 
\end{DoxySeeAlso}


Definition at line 98 of file Least\-Squares.\-h.

